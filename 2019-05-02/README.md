# M3 2019-05-02

## Schedule

### Thursday May 2, 2019 
**Time:** 6pm PST
  
**Agenda:** *([post agenda proposals here](https://github.com/open-metaverse-gathering/schedule/issues/1) )*
 - **Logistics:** 
   - Organization name
   - Meeting times
   - Meeting frequency
 - **Lightning Talks:**
   - Avaer https://youtu.be/vxcaBHuAEBk?t=1637
   - Jin https://youtu.be/vxcaBHuAEBk?t=2478
   - SM Sith Lord https://youtu.be/vxcaBHuAEBk?t=3956
   
   ------------------------------------------ 
   
 - **Topic of discussion:**
 https://youtu.be/vxcaBHuAEBk?t=5922
   
 In the context of past metaverse attempts: 
   
  - Why would this group be a significant?
  - Why is now a good time?
  - What if in the discussions the metaverse concept becomes too ephemeral and this turns into a philosophical time-waster?
    
 Skin in the game
   - How can we ensure group members have skin in the game and are incentivized to build rather than waste time?
    
 Group Hackathon
   - Focusing on building projects that promote compatibility
   
 GitHub
   - Repository to write down key organization values
   - Starting compatibility projects

	
   ------------------------------------------ 

## Timestamp Table

* [11:10](https://youtu.be/vxcaBHuAEBk?t=670) - Intro to organization
* [14:00](https://youtu.be/vxcaBHuAEBk?t=840) - Why is our attempt so different?
* [19:20](https://youtu.be/vxcaBHuAEBk?t=1160) - How can we find ways to foster this community?
* [21:21](https://youtu.be/vxcaBHuAEBk?t=1281) - What encourages people to build?
* [26:05](https://youtu.be/vxcaBHuAEBk?t=1568) - Cross-platform game idea
* [27:25](https://youtu.be/vxcaBHuAEBk?t=1646) - Avaer: How to not build a metaverse
* [35:04](https://youtu.be/vxcaBHuAEBk?t=2104) - QA: Unity the biggest force?
* [37:54](https://youtu.be/vxcaBHuAEBk?t=2275) - QA: How do we solve the web performance problem? 
* [41:20](https://youtu.be/vxcaBHuAEBk?t=2480) - Jin: Cross-linking virtual worlds
* [47:00](https://youtu.be/vxcaBHuAEBk?t=2820) - Opening a portal to google
* [49:05](https://youtu.be/vxcaBHuAEBk?t=2945) - QA: Protocol handlers
* [52:12](https://youtu.be/vxcaBHuAEBk?t=3132) - QA: Another layer beyond portals?
* [55:30](https://youtu.be/vxcaBHuAEBk?t=3330) - QA: Components with glTF and address bar
* [59:15](https://youtu.be/vxcaBHuAEBk?t=3555) - QA: Security regarding scripting
* [1:06:36](https://youtu.be/vxcaBHuAEBk?t=3996) - SithLord: What is a shortcut?
* [1:16:02](https://youtu.be/vxcaBHuAEBk?t=4562) - QA: Are you familiar with opengraph?
* [1:19:45](https://youtu.be/vxcaBHuAEBk?t=4785) - QA: How does Anarchy Arcade work? (Meta-tags)
* [1:21:30](https://youtu.be/vxcaBHuAEBk?t=4890) - QA: What's the best way to incentivize companies?
* [1:28:00](https://youtu.be/vxcaBHuAEBk?t=5280) - Security regarding websurfaces
* [1:33:02](https://youtu.be/vxcaBHuAEBk?t=5582) - Major obstacle with obtaining meta-tags
* [1:38:46](https://youtu.be/vxcaBHuAEBk?t=5926) - Recap last weeks topic regarding naming
* [1:46:30](https://youtu.be/vxcaBHuAEBk?t=6390) - What should we plan for next week?

---

#### Intro to Organization

T. [11:10](https://youtu.be/vxcaBHuAEBk?t=670)

Make sure we have compatibility across these different projects, there's a lot of great work being done but it can be most beneficial to be compatible and share things between projects. Separate silos are doing great things but if we can build things  between projects

This group is about interoperability between the platforms and frameworks.

Goes beyond just the software but the hardware as well. XR is a cross-organization, hardware, headset, platforms. There's a lot of raw talent that is working in silos doing awesome stuff but we're not talking to eachother quite enough to get that benefit for the thing we all really want to do is build a metaverse. We're looking at this from a full stack perspective to make all the pieces work together.

---

#### Why is our attempt different?

T. [14:00](https://youtu.be/vxcaBHuAEBk?t=840)

Now is the time because we now have a full stack which can be built upon current web technology. Back then hands-on research was inaccessible to regular developers. Its only recently that the hardware and software has hit a quality threshhold at a decent price point with a willingness of people to collaborate on higher goals. The platforms are becoming open and distributed enough that we can actually glue things together.

Full stack meaning full breadth from low-level (operating systems and hardware) to the high-level (engines and content frameworks).

There's other working groups like WebXR spec group which is very exclusive and partnerships with Qualcomm which are all under NDA which makes it hard to communicate with one another.

Other groups are philosophical and not really grounded in implementations. We want to be grounded in practical applications of these concepts.

S.M.A.R.T., or Specific, Measurable, Action-oriented, Realistic, and Time-stamped   <https://github.com/M3-org/proposals/issues/5#issuecomment-492815530>

---

#### How can we find ways to foster this community?

T. [19:20](https://youtu.be/vxcaBHuAEBk?t=1160)

- Virtual hackathons
- Game jams
- Field tests
- Mini-games

---

#### What encourages people to build?

T. [21:21](https://youtu.be/vxcaBHuAEBk?t=1281)

What encourages people to build instead of philosophizing about the metaverse?

If its fun, and fun to build, it will keep people motivated!

It helps to put out examples for letting people use the software and having a front-end for people to play with. Allows the technology to connect with the brain and generate fun.

Cross-platform / Cross-game event like a goosehunt.

---

#### Lightning Talk: How to Not Build a Metaverse

![](https://i.imgur.com/wyXcrRW.jpg)

T. [27:25](https://youtu.be/vxcaBHuAEBk?t=1646)

One of the reasons past attempts have failed is because they became silos that owned the data. However the metaverse already exists via the web, err but why does the metaverse not actually exist?

<https://github.com/M3-org/schedule/blob/master/2019-05-02/Avaer-how-not-to-build-a-metaverse.md>

Solution: emphasis on the **meta**

Ship the decoders for the data in our actual data

When you ship a website you also ship the frameworks you use with that website

Encapsulate all that in a website, ship that in webgl/webxr

Transport across platforms

Sounds like dat/ipfs protocol

Drop in a 3D url, becomes a 3D place

Make content we want to use but also want to make sure the content is built on some kinda standard we can agree on.

Permissionless innovation

Web is the metaverse, not quite there yet.

#### QA: Unity the biggest force in this space

T. [35:04](https://youtu.be/vxcaBHuAEBk?t=2104)

In some sense yes, Unity built business model around cross-linking different platforms but its controlled by a single for-profit entity that is highly incentivized by increasing shareholder value and not principles of an open decentralized metaverse.

#### QA: How do we solve the web performance problem? 

T. [37:54](https://youtu.be/vxcaBHuAEBk?t=2275)

Chrome is in many ways not incentivized to not take standards seriously or atleast take them in a different direction (make them secure by making your data hard to access besides Google)

Thick coats of paint between application you write and 

Exokit tries to be as close to hardware as possible: Javascript calls opengl directly.
Plans for WebGL implementation ontop of Vulkan.

Limitation of existing implementations

---

#### Jin: Cross-linking Virtual Worlds

![](https://i.imgur.com/z3HWYku.jpg)

T. [41:20](https://youtu.be/vxcaBHuAEBk?t=2480)

**Writeup**: <https://gist.github.com/madjin/ff580a7bbe6cc077cc87c3971801b99f>

Moving avatars and objects between virtual worlds.

In 2D web we can click a link, so how do hyperlinks translate into a 3D web?

Sliding scale of interoperability:

Level 1: Hyperlinks
Level 2: Pass-through portal
Level 3: Seamless portal transition

![](https://i.imgur.com/B1iSjRX.gif)

---

#### Protocol Handlers

T. [49:05](https://youtu.be/vxcaBHuAEBk?t=2945)

Launching stuff from protocol handlers

Cryptovoxels supports `steam://`, `hifi://`, `vrchat://`, and `http://`

Demo: <https://www.cryptovoxels.com/play?coords=N@214E,3U,27S>

JanusWeb has support for ipfs and dat

Some might need extensions or gateways

Needs to get installed on the system before handling them (run atleast once)

Goals in long-term is overlay (like PlutoVR) bridge gap between 2D and 3D program

Can shoot portal onto a surface of an object and walk into another game

Like an iframe in 3D space?

---

#### Another layer beyond portals

T. [52:12](https://youtu.be/vxcaBHuAEBk?t=3132)

Not necessarily portals but anything being a URL even objects, avatars, and places

URLs you can load and composite in your world (like Reality Layers or Tabs)

Portal is essentially a stencil shader that you can composite with a depth buffer

Oculus home makes use of interactive 3D objects that can launch shortcuts

Doing things across websites or native apps, as long as you can get access to frame and depth buffer at reasonable framerate you can composite things together that weren't designed to be interconnected.

Vulkan can improve this

Links can be represented in many different ways on a sliding scale of interoperability

GET/POST from browser rendering perspective

---

#### Components with glTF and address bar

T. [55:30](https://youtu.be/vxcaBHuAEBk?t=3330)

Mozilla folks have used GLTF extensions to annotate objects with components

How something like scripting can work with this?

Is glTF HTML, extension to add behavior?

Curious if thought about web browser - top bar is sacred region that is untouched

How do you know where you're going?

Navigation UI component in JanusWeb 

---

#### Security regarding scripting

T. [59:15](https://youtu.be/vxcaBHuAEBk?t=3555)

Way Google has interpreted it is that security is basically impossible with navigation so they're basically banning it on that basis: anyone can spoof the URL bar.

Trust the UI: things only you could know?

Decent dedicated hardware on wrist / watch that you can't spoof (I'm actually at this URL)

Trust has to start somewhere, what is the root of the trust tree?

In exokit, everything is completely isolated (separate rendering).

Only way things can leak is via user input, besides that they cannot interact with each other.

Virtual keyboard -> by virtue of what user is doing with hands can infer what password is.

One of things Janus did is at client level, if you have a box over input box, stop rendering / sending data (like hand positions) through the multiplayer server.

Certain input boxes block what other scripts can see.

Certain multiplayer protocols as standard (unified API we can use and browsers can know this is how the data is coming in so rational security protocols can get implemented).

No one doing banking in VR yet, we're still experimenting to see what's possible before locking things down.

One thing JanusWeb looked at where running mode where things are a bit more locked down as client option.

Things get interesting where notion of identifying content in space or volume, can securely lock it within that volume for inputs only.

QubesOS: secure OS architecture - everything is sandboxed so if one gets pwned it doesn't affect everything else.

Make sure boundaries aren't leaked.

Cross-origin type things in XR

JanusWeb: room scripts run in same context right now, but if you run in a worker thread you can keep in sandbox but have to provide bridge API to sync the scripts with the world/render state.

Iframe API and Iframe loads in entirely separate context, composited by user-agent.

Stack iframes in layers array. These iframes do not know about each other unless you choose for them to know about each other.

---

#### SithLord: What is a Shortcut?

![](https://i.imgur.com/nX84fyu.jpg)

T. [1:06:36](https://youtu.be/vxcaBHuAEBk?t=3996)

Shortcuts are something we use everyday!

The metaverse is kind of like the web, the web is like the metaverse just not visualized in a 3D way yet.

All the 2D stuff is going to come with us into the next dimension.

Shortcuts is how we get around, we use them all the time on our phones, browsers, desktops, steam, etc.

The most important part of the shorcut is the file target, address, where you're going - the destination.

What makes it look nice? 

If you think of a GPS coordinate you can get there but what is it?

Add meta-tags / metadata to the shortcut for it to make more sense

Tag Los Angeles California to GPS coordinate - bam

Icon / screenshots as more tags to give shortcut more representation.

When you look at desktop you are seeing shortcuts - extra metatags give them richer presence in the world.

Rich presence for the destination: Its not just a GPS coordinate, its Los Angeles California!

Representing shortcuts in the metaverse is going to be huge

Shorcuts have always been there since dawn of computing.

When you browse netflix, it has marquee image / title / and preview windows.

SteamVR home and Oculus home does this on same kind of level - spawn shortcuts as 3D objects.

If you look at someone elses desktop it looks like a bunch of crap, but if you saw your desktop you'd recognize it all - has a personal connection to you.

They're shortcuts but to the people that created them - these shortcuts are their representations of what the metaverse is and what matters to them the most.

Visualize the same exact shortcuts in a new way, that personal value will transfer over to the next dimension.

When looking at shortcuts, visualize how they will look in different platforms.

If you took your shortcuts from desktop / bookmarks into a 3D world, what would it look like?

Lets make the shorcuts look good, then we'll work our way up to better transitions.

AA is a frontend for customizing and launching shortcuts in a 3D world.

#### QA: Are you familiar with Opengraph?

T. [1:16:02](https://youtu.be/vxcaBHuAEBk?t=4562)

Web effort to provide descriptions for content.

Database of icons

For example if you drop URL in discord sometimes it will have image/video preview. Invert content.

If publish website, put tags in page to cull out that this URL represents a video and heres a URL to thmbnail, description, title, etc. Tags.

Metatag standards and APIs are wonderful, sometimes you can't put all information in tags so some corporations have APIs.

When you go to website, it'd be nice if they follow these standards - leverage them if they have them.

If they have information there in metatags that's wonderful. They're great but not up to par - if you look at Netflix / Hulu they have more than 1 image per entry in database and preview video associated with it. While standards are great it seems they're falling behind what Hulu/Netflix are doing. If you give me 1 image what can I do? Put it on tablet mostly..

Extra fields will give extra rich presence of the shortcut.

It'd be great to see the stuff Netflix/Hulu use to be adopted more in websites.

There's a mailing list for opengraph, launched sometime in 2009.

#### QA: How does Anarchy Arcade work?

![](https://i.imgur.com/KPnCvGA.jpg)

T. [1:19:45](https://youtu.be/vxcaBHuAEBk?t=4785)

Wizard scrapes meta-tags from websites to fill the input fields for the shortcut. Can fill out shortcut properties manually as well like how one would with traditional desktop icons.

#### QA: What's the best way to incenvitize companies?

T. [1:21:30](https://youtu.be/vxcaBHuAEBk?t=4890)

What can we do to incentive companies to adopt meta-tag standards?

Users often manually fine-tune shortcuts.

Stuff you give default shortcuts and icons are starting points, can provide better customization with assets the user owns.

---

#### Security regarding websurfaces

T. [1:28:00](https://youtu.be/vxcaBHuAEBk?t=5280)

2D web content in WebGL

Loading a whole browser inside a 3D engine

Display webpages in a 3D world

DOM to texture

No infrastructure to get 2D web content in 3D web pages

Opengraph 3D

You can't render a web tab - giving pixel access is a potential vulnerability for hackers

This is partly being addressed in spec groups

Problem is that browser has cookies and cross-domain issues and capture issues

If user has cursor looking at 2D page, 2D page could be bank account, by clicking on page can deduce what sensitive information is

Prevents browsers from implementing DOM to texture stuff

They are solving some of this in spec as long as you follow cross-origin rules you can composite

Will not be able to access pixels directly - user agent specified by transform

Currently if you open full web tab its a security hole 

AA is like desktop that launches shortcuts: when you launch something there's no connection

AA is not scripting platform, people defining properties not logic

Exokit allows this stuff, users need to understand security impact of what they're doing

Web has 25 years of training users what green / lock icon means

Teach people correct browsing habits in XR space

---

#### Obstacles when obtaining the meta-tags

T. [1:33:02](https://youtu.be/vxcaBHuAEBk?t=5582)

Each website has to be custom implemented for scrapers

Not enough data / standards

Writing JS scrapers for every website is a huge task

Really is no current solution yet, some sites will not open up their API (netflix for example)

The idea is that big companies want to show users their representation of the content (some ads, whats featured, similar interests) but sometimes users want to cut the fat.

Netflix will only serve up to 720p

Because of DRM they will not serve up the full 4k stream

It's not leeching, its consuming in a 3D environment.


---

## Wrapping up

* [1:38:46](https://youtu.be/vxcaBHuAEBk?t=5926) - Recap last weeks topic regarding naming
* [1:46:30](https://youtu.be/vxcaBHuAEBk?t=6390) - What should we plan for next week?
